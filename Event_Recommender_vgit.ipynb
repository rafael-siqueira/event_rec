{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re #regex\n",
    "import time\n",
    "from unicodedata import normalize\n",
    "import requests as rq\n",
    "import bs4 as bs4 #beautifulsoup4\n",
    "import json\n",
    "import tqdm\n",
    "import glob\n",
    "import joblib as jb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP tools\n",
    "from more_itertools import unique_everseen\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "stop_pt = stopwords.words('portuguese')\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Model optimization\n",
    "from skopt import forest_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max.columns\", 100)\n",
    "pd.set_option('display.min_rows', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is based on the YouTube Video Recommender project designed and taught by Mário Filho on his Hotmart course  \n",
    "I decided to do something similar but trying to predict events that I would like to attend in São Paulo. For that, I collected information from events from two ticket-selling aggregator websites: Sympla and Eventbrite, manually labeled them and fit several models to evaluate which one had better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting search pages - Sympla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request headers\n",
    "headers_sympla = {'authority': 'www.sympla.com.br',\n",
    "           'method': 'GET',\n",
    "           'path': '/eventos/sao-paulo-sp?ordem=data&pagina=2&value=sao-paulo-sp',\n",
    "           'scheme': 'https',\n",
    "           'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', \n",
    "           'accept-encoding': 'gzip, deflate, br',\n",
    "           'accept-language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'sec-fetch-dest': 'document',\n",
    "           'sec-fetch-mode': 'navigate',\n",
    "           'sec-fetch-site': 'none',\n",
    "           'upgrade-insecure-requests': '1',\n",
    "           'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_sympla = 'https://www.sympla.com.br/eventos/sao-paulo-sp?ordem=data&pagina={page}&value=sao-paulo-sp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I ran this code, there were 49 search pages available\n",
    "for page in range(1,50):\n",
    "    url = url_sympla.format(page=page)\n",
    "    print(url)\n",
    "    response = rq.get(url, headers=headers_sympla)\n",
    "        \n",
    "    with open(\"./Raw_Data/Sympla_{}.html\".format(page), 'w+', encoding='utf-8') as output:\n",
    "        output.write(response.text)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1,50):\n",
    "    with open(\"./Raw_Data/Sympla_{}.html\".format(page), \\\n",
    "              'r+', encoding='utf-8') as inp:\n",
    "        html_page = inp.read()\n",
    "        parsed_html = bs4.BeautifulSoup(html_page)\n",
    "        tags = parsed_html.find_all('a', attrs={'class': 'sympla-card card-normal w-inline-block'})\n",
    "        \n",
    "        for t in tags:\n",
    "            # Link\n",
    "            link = t['href']\n",
    "            \n",
    "            # Name\n",
    "            name_aux = t.find('div', attrs={'class': 'event-name event-card'}).text\n",
    "            name = re.sub(' +', ' ', name_aux)\n",
    "            \n",
    "            # Location\n",
    "            location_aux = t.find('div', attrs={'class': 'event-location event-card'}).text.strip()\n",
    "            location = re.sub(' +', ' ', location_aux)\n",
    "            \n",
    "            # Date\n",
    "            if t.find('div', attrs={'class': 'event-date-day'}) != None:\n",
    "                event_day = t.find('div', attrs={'class': 'event-date-day'}).text\n",
    "                event_month = t.find('div', attrs={'class': 'event-card-date-month'}).text\n",
    "                date = \" \".join([event_day, event_month])\n",
    "            else:\n",
    "                date = np.nan\n",
    "            \n",
    "            with open(\"./parsed_events_sympla.json\", \\\n",
    "                          'a+', encoding='utf-8') as outp:\n",
    "                event_data = {\"link\": link, \"name\": name, \"location\": location, 'date': date}\n",
    "                outp.write(\"{}\\n\".format(json.dumps(event_data, ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting search pages - Eventbrite (EB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_eventbrite = 'https://www.eventbrite.com.br/d/brazil--s%C3%A3o-paulo/all-events/?page={page}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When I ran this code, there were 43 search pages available\n",
    "for page in range(1,44):\n",
    "    url = url_eventbrite.format(page=page)\n",
    "    print(url)\n",
    "    response = rq.get(url)\n",
    "        \n",
    "    with open(\"./Raw_Data/Eventbrite_{}.html\".format(page), 'w+', encoding='utf-8') as output:\n",
    "        output.write(response.text)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1,44):\n",
    "    with open(\"./Raw_Data/Eventbrite_{}.html\".format(page), \\\n",
    "              'r+', encoding='utf-8') as inp:\n",
    "        html_page = inp.read()\n",
    "        parsed_html = bs4.BeautifulSoup(html_page)\n",
    "        tags = parsed_html.find_all('div', attrs={'class': 'eds-event-card-content__content'})\n",
    "        \n",
    "        for t in tags:\n",
    "            # Link\n",
    "            link = t.find('a', attrs={'class': 'eds-event-card-content__action-link'})['href']\n",
    "            \n",
    "            # Name\n",
    "            name_aux = t.find('div', attrs={'class': 'eds-is-hidden-accessible'}).text\n",
    "            name = re.sub(' +', ' ', name_aux)\n",
    "            \n",
    "            # Location\n",
    "            location_aux = t.find('div', attrs={'class': 'card-text--truncated__one'}).text\n",
    "            location = re.sub(' +', ' ', location_aux)\n",
    "            \n",
    "            # Date\n",
    "            date_aux = t.find('div', attrs={'class': \\\n",
    "                                                    'eds-text-color--primary-brand eds-l-pad-bot-1 eds-text-weight--heavy eds-text-bs'}).text\n",
    "            date = re.sub(' +', ' ', date_aux)\n",
    "        \n",
    "            with open(\"./parsed_events_eb.json\", \\\n",
    "                          'a+', encoding='utf-8') as outp:\n",
    "                event_data = {\"link\": link, \"name\": name, \"location\": location, \"date\": date}\n",
    "                outp.write(\"{}\\n\".format(json.dumps(event_data, ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking search pages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 4)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_sympla = pd.read_json(\"./parsed_events_sympla.json\", lines=True)\n",
    "events_sympla = events_sympla.drop_duplicates().reset_index(drop=True)\n",
    "events_sympla.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729, 4)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_eb = pd.read_json(\"./parsed_events_eb.json\", lines=True)\n",
    "events_eb = events_eb.drop_duplicates().reset_index(drop=True)\n",
    "events_eb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.eventbrite.com.br/e/conexao-teen-m...</td>\n",
       "      <td>CONEXÃO TEEN - MINISTROS</td>\n",
       "      <td>Renascer Hall • Mooca, SP</td>\n",
       "      <td>sáb, out 24, 14:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.eventbrite.com.br/e/mini-bazar-clo...</td>\n",
       "      <td>Mini Bazar Clozét (HORA MARCADA E ENTRADA CONT...</td>\n",
       "      <td>Rua Antônio Salvia, 252 • Parque Maria Helena, SP</td>\n",
       "      <td>sáb, out 24, 09:00 + 7 eventos mais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.eventbrite.com.br/e/hub-surrender-...</td>\n",
       "      <td>HUB SURRENDER - 24/10 - 19h</td>\n",
       "      <td>Harvest Field Church • Barra Funda, SP</td>\n",
       "      <td>sáb, out 24, 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.eventbrite.com/e/dna-diferente-32-...</td>\n",
       "      <td>DNA DIFERENTE (32 )</td>\n",
       "      <td>Holiday Inn Sao Paulo Parque Anhembi • Parque ...</td>\n",
       "      <td>sáb, nov 21, 08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.eventbrite.com/e/culto-iasd-pinhei...</td>\n",
       "      <td>Culto IASD Pinheiros</td>\n",
       "      <td>R. Cláudio Soares, 167 • Pinheiros, SP</td>\n",
       "      <td>sáb, out 24, 09:00 + 42 eventos mais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.eventbrite.com.br/e/conexao-teen-m...   \n",
       "1  https://www.eventbrite.com.br/e/mini-bazar-clo...   \n",
       "2  https://www.eventbrite.com.br/e/hub-surrender-...   \n",
       "3  https://www.eventbrite.com/e/dna-diferente-32-...   \n",
       "4  https://www.eventbrite.com/e/culto-iasd-pinhei...   \n",
       "\n",
       "                                                name  \\\n",
       "0                           CONEXÃO TEEN - MINISTROS   \n",
       "1  Mini Bazar Clozét (HORA MARCADA E ENTRADA CONT...   \n",
       "2                        HUB SURRENDER - 24/10 - 19h   \n",
       "3                                DNA DIFERENTE (32 )   \n",
       "4                               Culto IASD Pinheiros   \n",
       "\n",
       "                                            location  \\\n",
       "0                          Renascer Hall • Mooca, SP   \n",
       "1  Rua Antônio Salvia, 252 • Parque Maria Helena, SP   \n",
       "2             Harvest Field Church • Barra Funda, SP   \n",
       "3  Holiday Inn Sao Paulo Parque Anhembi • Parque ...   \n",
       "4             R. Cláudio Soares, 167 • Pinheiros, SP   \n",
       "\n",
       "                                   date  \n",
       "0                    sáb, out 24, 14:30  \n",
       "1   sáb, out 24, 09:00 + 7 eventos mais  \n",
       "2                    sáb, out 24, 19:00  \n",
       "3                    sáb, nov 21, 08:00  \n",
       "4  sáb, out 24, 09:00 + 42 eventos mais  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_eb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting event pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_events_pages(links_series, platform, headers=None):\n",
    "    for url in links_series:\n",
    "        print(url)\n",
    "        response = rq.get(url, headers=headers)\n",
    "        \n",
    "        if platform == 'eventbrite':\n",
    "            link_name = re.search(\"e/(.*)\\?\", url).group(1)\n",
    "            files_location = \"./Raw_Data/Events_EB/{}.html\"\n",
    "\n",
    "        elif platform == 'sympla':\n",
    "            if re.search(\"bileto\", url) != None:\n",
    "                continue\n",
    "            else:\n",
    "                link_name = re.search(\"br/(.*)\", url).group(1)\n",
    "            \n",
    "            files_location = \"./Raw_Data/Events_Sympla/{}.html\"\n",
    "            \n",
    "        with open(files_location.format(link_name), 'w+', encoding='utf-8') as outp:\n",
    "            outp.write(response.text)\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_series_eb = events_eb['link']\n",
    "links_series_sympla = events_sympla['link']\n",
    "save_events_pages(links_series_eb, platform='eventbrite')\n",
    "save_events_pages(links_series_sympla, platform='sympla', headers=headers_sympla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing event pages - EB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 729/729 [01:02<00:00, 11.65it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./parsed_events_info_eb.json\", 'w+', encoding='utf-8') as output:\n",
    "    for event_html in tqdm.tqdm(glob.glob(\"./Raw_Data/Events_EB/*\")):\n",
    "        with open(event_html, 'r+', encoding='utf-8') as inp:\n",
    "            html_page = inp.read()\n",
    "            parsed_html = bs4.BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "            # Name, only 1\n",
    "            name = None\n",
    "            if parsed_html.find('h1', attrs={\"class\":re.compile(r\"listing\")}) != None:\n",
    "                name = parsed_html.find('h1', attrs={\"class\":re.compile(r\"listing\")}).text.strip()\n",
    "            # Organizer, only 1\n",
    "            organizer = parsed_html.find('div', attrs={\"class\":re.compile(r\"title\")}).text.strip()  \n",
    "            # Description, several\n",
    "            content_cols = parsed_html.find_all('div', attrs={\"class\":re.compile(r\"content\")})\n",
    "            # Dates, several\n",
    "            time_cols = parsed_html.find_all('p', attrs={'class', re.compile(r\"time\")})\n",
    "            # Location, several\n",
    "            location_cols = parsed_html.find_all(\"div\", attrs={'class': 'event-details__data'})\n",
    "            # Labels, several\n",
    "            labels_aux = parsed_html.find_all('a', attrs={'class': 'js-d-track-link listing-tag badge badge--tag l-mar-top-2'})\n",
    "            # Price, only 1\n",
    "            price = None\n",
    "            if parsed_html.find(\"div\", attrs={'class': 'js-display-price'}) != None:\n",
    "                price = parsed_html.find(\"div\", attrs={'class': 'js-display-price'}).text.strip()\n",
    "            # Other info, only 1\n",
    "            info = None\n",
    "            if parsed_html.find(\"div\", attrs={'class': 'listing-panel-info__sm-text-center'}) != None:\n",
    "                info = parsed_html.find(\"div\", attrs={'class': 'listing-panel-info__sm-text-center'}).text.strip()\n",
    "\n",
    "            event_data = dict()\n",
    "            event_data['name'] = name\n",
    "            event_data['organizer'] = organizer\n",
    "            event_data['price'] = price\n",
    "            event_data['info'] = info\n",
    "            labels = [l.text.strip() for l in labels_aux]\n",
    "            event_data['labels'] = \" \".join(labels)\n",
    "\n",
    "            # Creating several columns\n",
    "            for c in content_cols:\n",
    "                col_name = \"_\".join(c['class'])\n",
    "                event_data[col_name] = c.get_text(\" \").strip()\n",
    "\n",
    "            for c in time_cols:\n",
    "                col_name = \"_\".join(c['class'])\n",
    "                event_data[col_name] = c.get_text(\" \").strip()\n",
    "\n",
    "            for c in location_cols:\n",
    "                col_name = \"_\".join(c['class'])\n",
    "                event_data[col_name] = c.get_text(\" \").strip()\n",
    "\n",
    "            output.write(\"{}\\n\".format(json.dumps(event_data, ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing event pages - Sympla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 889/889 [01:32<00:00,  9.64it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"./parsed_events_info_sympla.json\", 'w+', encoding='utf-8') as output:\n",
    "    for event_html in tqdm.tqdm(glob.glob(\"./Raw_Data/Events_Sympla/*\")):\n",
    "        with open(event_html, 'r+', encoding='utf-8') as inp:\n",
    "            html_page = inp.read()\n",
    "            parsed_html = bs4.BeautifulSoup(html_page, 'html.parser')\n",
    "            \n",
    "            # Name\n",
    "            name = parsed_html.find('h1').text.strip()\n",
    "            # Dates\n",
    "            date = None\n",
    "            if parsed_html.find('div', attrs={\"class\":'event-info-calendar'}) != None:\n",
    "                date = parsed_html.find('div', attrs={\"class\":'event-info-calendar'}).text.strip()\n",
    "            # Location\n",
    "            location = None\n",
    "            if parsed_html.find('div', attrs={\"class\":'event-info-city'}) != None:\n",
    "                location = parsed_html.find('div', attrs={\"class\":'event-info-city'}).text.strip()\n",
    "            # Organizer\n",
    "            organizer = None\n",
    "            if parsed_html.find('div', attrs={\"id\":'produtor'}) != None:\n",
    "                org_aux = parsed_html.find('div', attrs={\"id\":'produtor'})\n",
    "                if org_aux.find('h4', attrs={\"class\":re.compile(r\"kill\")}) != None:\n",
    "                    organizer = org_aux.find('h4', attrs={\"class\":re.compile(r\"kill\")}).text.strip()\n",
    "            # Organizer description\n",
    "            org_desc = None\n",
    "            if org_aux.find('p', attrs={\"id\":'org-description'}) != None:\n",
    "                org_desc = org_aux.find('p', attrs={\"id\":'org-description'}).text.strip()\n",
    "                org_desc = re.sub(' +', ' ', org_desc)\n",
    "            # Description\n",
    "            description = None\n",
    "            if parsed_html.find('div', attrs={\"id\":'event-description'}) != None:\n",
    "                description = parsed_html.find('div', attrs={\"id\":'event-description'}).get_text(\" \").strip()\n",
    "                description = re.sub(' +', ' ', description)\n",
    "            # Price, first one\n",
    "            price = None\n",
    "            if parsed_html.find('form', attrs={\"id\":'ticket-form'}) != None:\n",
    "                price_aux = parsed_html.find('form', attrs={\"id\":'ticket-form'})\n",
    "                if len(price_aux.find_all('span')) >= 3:\n",
    "                    price = price_aux.find_all('span')[2].text.strip()\n",
    "            # Other info\n",
    "            info = None\n",
    "            if parsed_html.find('td', attrs={'class':'opt-panel'}) != None:\n",
    "                info = parsed_html.find('td', attrs={'class':'opt-panel'}).text.strip()\n",
    "            # Labels\n",
    "            # NA\n",
    "    \n",
    "            event_data = dict()\n",
    "            event_data['name'] = name\n",
    "            event_data['date'] = date\n",
    "            event_data['location'] = location\n",
    "            event_data['price'] = price\n",
    "            event_data['info'] = info\n",
    "            event_data['description'] = description\n",
    "            event_data['organizer'] = organizer\n",
    "            event_data['org_desc'] = org_desc\n",
    "\n",
    "            output.write(\"{}\\n\".format(json.dumps(event_data, ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading collected information for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_map = {\"dom\": 0, \"sun\": 0,\n",
    "               \"seg\": 1, \"mon\": 1,\n",
    "               \"ter\": 2, \"tue\": 2, \n",
    "               \"qua\": 3, \"wed\": 3, \n",
    "               \"qui\": 4, \"thu\": 4, \"quinta\": 4,\n",
    "               \"sex\": 5, \"fri\": 5, \n",
    "               \"sab\": 6, \"sat\": 6, \"sabado\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_map = {\"janeiro\": \"Jan\",\n",
    "              \"fevereiro\": \"Feb\",\n",
    "              \"marco\": \"Mar\", \n",
    "              \"abril\": \"Apr\", \n",
    "              \"maio\": \"May\", \n",
    "              \"junho\": \"Jun\",\n",
    "              \"julho\": \"Jul\",\n",
    "              \"agosto\": \"Aug\", \n",
    "              \"setembro\": \"Sep\", \n",
    "              \"outubro\": \"Oct\", \n",
    "              \"novembro\": \"Nov\",\n",
    "              \"dezembro\": \"Dec\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>price</th>\n",
       "      <th>info</th>\n",
       "      <th>description</th>\n",
       "      <th>organizer</th>\n",
       "      <th>org_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/11 - Culto de Domingo - Manhã</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Inscrições até 01/11/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Igreja Monte Carmelo</td>\n",
       "      <td>Conheça-nos melhor\\n\\nhttp://monte-carmelo.onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/11 - Culto de Domingo - Noite</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Inscrições até 01/11/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Igreja Monte Carmelo</td>\n",
       "      <td>Conheça-nos melhor\\n\\nhttp://monte-carmelo.onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/11- Culto de Quinta</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Inscrições até 05/11/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Igreja Monte Carmelo</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10º ESLADJA E 22º ANIVERSARIO DA ADJA-TRABALHA...</td>\n",
       "      <td>14 de novembro de 2020, 14h30&gt;21h</td>\n",
       "      <td>R. Uhland, 204 - São Paulo, SP</td>\n",
       "      <td>R$ 25,00</td>\n",
       "      <td>0</td>\n",
       "      <td>Em breve acontecerá a nossa 10ª ESLADJA - ESCO...</td>\n",
       "      <td>[email protected]</td>\n",
       "      <td>Igreja Evangélica Assembleia de Deus-Ministéri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15º Piquenique Azul</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Inscrições até 22/11/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Nathália Noschese - Natype1</td>\n",
       "      <td>Nathália Noschese é uma jovem que tem Diabetes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                   01/11 - Culto de Domingo - Manhã   \n",
       "1                   01/11 - Culto de Domingo - Noite   \n",
       "2                             05/11- Culto de Quinta   \n",
       "3  10º ESLADJA E 22º ANIVERSARIO DA ADJA-TRABALHA...   \n",
       "4                                15º Piquenique Azul   \n",
       "\n",
       "                                date                        location  \\\n",
       "0                               None                            None   \n",
       "1                               None                            None   \n",
       "2                               None                            None   \n",
       "3  14 de novembro de 2020, 14h30>21h  R. Uhland, 204 - São Paulo, SP   \n",
       "4                               None                            None   \n",
       "\n",
       "                       price info  \\\n",
       "0  Inscrições até 01/11/2020    0   \n",
       "1  Inscrições até 01/11/2020    0   \n",
       "2  Inscrições até 05/11/2020    0   \n",
       "3                   R$ 25,00    0   \n",
       "4  Inscrições até 22/11/2020    0   \n",
       "\n",
       "                                         description  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  Em breve acontecerá a nossa 10ª ESLADJA - ESCO...   \n",
       "4                                               None   \n",
       "\n",
       "                     organizer  \\\n",
       "0         Igreja Monte Carmelo   \n",
       "1         Igreja Monte Carmelo   \n",
       "2         Igreja Monte Carmelo   \n",
       "3            [email protected]   \n",
       "4  Nathália Noschese - Natype1   \n",
       "\n",
       "                                            org_desc  \n",
       "0  Conheça-nos melhor\\n\\nhttp://monte-carmelo.onl...  \n",
       "1  Conheça-nos melhor\\n\\nhttp://monte-carmelo.onl...  \n",
       "2                                               None  \n",
       "3  Igreja Evangélica Assembleia de Deus-Ministéri...  \n",
       "4  Nathália Noschese é uma jovem que tem Diabetes...  "
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_info_sympla_raw = pd.read_json(\"./parsed_events_info_sympla.json\", lines=True)\n",
    "events_info_sympla_raw.dropna(axis=0, subset=['name'], inplace=True)\n",
    "events_info_sympla_raw = events_info_sympla_raw.reset_index(drop=True)\n",
    "events_info_sympla_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_info_sympla = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_info_eb_raw = pd.read_json(\"./parsed_events_info_eb.json\", lines=True)\n",
    "events_info_eb_raw.dropna(axis=0, subset=['name'], inplace=True)\n",
    "events_info_eb_raw = events_info_eb_raw.reset_index(drop=True)\n",
    "events_info_eb = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions to process columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(series):\n",
    "    return series.str.replace(\"\\n|\\t\",\"\").str.replace(\" +\",\" \").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accented characters, punctuation and uppercase\n",
    "def normalize_series(series):\n",
    "    processed = []\n",
    "    processed = [normalize('NFKD', value).encode('ASCII','ignore').decode('ASCII') \\\n",
    "           if (value != None) & (value != np.nan) & (type(value) != float) else np.nan for index, value in series.items()]\n",
    "    return remove_whitespace(pd.Series(processed).str.lower().str.replace(r\"[^a-zA-Z0-9]\",\" \").str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(series):\n",
    "    return series.str.replace(r\"[0-9]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mean price when there is a range of ticket prices\n",
    "def determine_price(row):\n",
    "    if row[1] < row[0]:\n",
    "        return row[0]\n",
    "    else:\n",
    "        return (row[0]+row[1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specific non-definitional words from all events\n",
    "def clean_description(series):\n",
    "    return series.str.replace('(sobre este evento)|(about this event)|(a propos de cet evenement)|(acerca deste evento)|(acerca de este evento)', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_na(row):\n",
    "    if type(row[0]) != float:\n",
    "        return \" \".join(row)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to process each column as follows:\n",
    "- Name: make it lowercase, remove punctuation, accented chars and numbers\n",
    "- Date: use day of week (DOW) as possible feature\n",
    "- Location: make it lowercase, remove punctuation, accented chars and numbers\n",
    "- Price: use mean or lowest price\n",
    "- Info: make it lowercase, remove punctuation, accented chars and numbers\n",
    "- Description: make it lowercase, remove punctuation, accented chars\n",
    "- Organizer: make it lowercase, remove punctuation, accented chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing columns - EB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "events_info_eb['name'] = remove_whitespace(remove_numbers(normalize_series(events_info_eb_raw['name'])))\n",
    "\n",
    "# DOW\n",
    "events_info_eb_raw.rename(columns={'js-date-time-first-line':'full_date'}, inplace=True)\n",
    "events_info_eb['dow'] = events_info_eb_raw['full_date'].str.extract('(.*?),', expand=False).str.lower().str.replace('á','a').map(week_map)\n",
    "\n",
    "# Location\n",
    "events_info_eb_raw.rename(columns={'event-details__data':'location_raw'}, inplace=True)\n",
    "location_aux = pd.Series(dtype='object')\n",
    "location_aux = remove_whitespace(events_info_eb_raw['location_raw'].str.replace('Ver mapa',''))\n",
    "events_info_eb['location'] = remove_whitespace(remove_numbers(normalize_series(location_aux)))\n",
    "\n",
    "# Price; if null, event is free\n",
    "events_info_eb_raw['full_price'] = events_info_eb_raw['price']\n",
    "events_info_eb_raw.loc[(events_info_eb_raw['full_price'] == '') | (events_info_eb_raw['full_price'] == 'Free') | \\\n",
    "                   (events_info_eb_raw['full_price'] == 'Gratuito') | (events_info_eb_raw['full_price'] == 'Gratuit'),'full_price'] = 'R$0'\n",
    "# Fetching range of prices\n",
    "price_aux = events_info_eb_raw['full_price'].str.replace('\\.|[A-Z]|\\$|\\s','').str.replace('\\,','.').str.extract(r'(\\d+)–*(\\d*)')\n",
    "price_aux[0] = pd.to_numeric(price_aux[0], downcast='float')\n",
    "price_aux[1] = pd.to_numeric(price_aux[1], downcast='float')\n",
    "# Lowest price\n",
    "events_info_eb_raw['min_price'] = price_aux[0]\n",
    "# Highest price\n",
    "price_aux.loc[price_aux[1].isna(), 1] = 0\n",
    "events_info_eb_raw['max_price'] = price_aux[1]\n",
    "# Feature price\n",
    "events_info_eb['price'] = pd.Series(price_aux.apply(determine_price, axis=1), dtype='float')\n",
    "\n",
    "# Info\n",
    "events_info_eb['info'] = remove_whitespace(remove_numbers(normalize_series(events_info_eb_raw['info'])))\n",
    "\n",
    "# Description\n",
    "events_info_eb_raw.rename(columns={'structured-content_g-cell_g-cell-10-12_g-cell-md-1-1':'description_raw'}, inplace=True)\n",
    "events_info_eb['description'] = remove_whitespace(clean_description(normalize_series(events_info_eb_raw['description_raw'])))\n",
    "\n",
    "# Organizer\n",
    "events_info_eb_raw.loc[events_info_eb_raw['organizer'] == '', 'organizer'] = None\n",
    "org_aux = events_info_eb_raw['organizer'].str.replace('por |by ','')\n",
    "events_info_eb['organizer'] = remove_whitespace(normalize_series(org_aux))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing columns - Sympla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "events_info_sympla['name'] = remove_whitespace(remove_numbers(normalize_series(events_info_sympla_raw['name'])))\n",
    "\n",
    "# DOW\n",
    "date_aux = normalize_series(events_info_sympla_raw['date'])\n",
    "date_aux = date_aux.str.extract(r'^(\\d+) de ([a-z]+) de (\\d+)')\n",
    "date_aux[1] = date_aux[1].map(month_map)\n",
    "date_aux = date_aux.apply(join_na, axis=1)\n",
    "date_aux = pd.to_datetime(date_aux, format=\"%d %b %Y\")\n",
    "events_info_sympla['dow'] = date_aux.dt.dayofweek\n",
    "\n",
    "# Location\n",
    "events_info_sympla['location'] = remove_whitespace(remove_numbers(normalize_series(events_info_sympla_raw['location'])))\n",
    "\n",
    "# Price; if null, event is free\n",
    "events_info_sympla_raw.loc[events_info_sympla_raw['price'].isnull(), 'price'] = 'R$ 0'\n",
    "price_aux = events_info_sympla_raw['price'].str.replace('\\.|R\\$|\\s','').str.replace('\\,','.')\n",
    "price_aux[price_aux.str.contains('[azAZ]')] = 0\n",
    "events_info_sympla['price'] = pd.Series(price_aux, dtype='float')\n",
    "\n",
    "# Info\n",
    "events_info_sympla_raw.loc[events_info_sympla_raw['info'] == '0', 'info'] = float('nan')\n",
    "events_info_sympla['info'] = remove_whitespace(remove_numbers(normalize_series(events_info_sympla_raw['info'])))\n",
    "\n",
    "# Description\n",
    "events_info_sympla['description'] = remove_whitespace(normalize_series(events_info_sympla_raw['description']))\n",
    "\n",
    "# Organizer\n",
    "events_info_sympla['organizer'] = remove_whitespace(normalize_series(events_info_sympla_raw['organizer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dow</th>\n",
       "      <th>location</th>\n",
       "      <th>price</th>\n",
       "      <th>info</th>\n",
       "      <th>description</th>\n",
       "      <th>organizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>culto de domingo manha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>igreja monte carmelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culto de domingo noite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>igreja monte carmelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>culto de quinta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>igreja monte carmelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o esladja e o aniversario da adja trabalhando ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>r uhland sao paulo sp</td>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>em breve acontecera a nossa 10a esladja escola...</td>\n",
       "      <td>email protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o piquenique azul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nathalia noschese natype1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>xvi jornada paulista de neurofisiologia clinica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hospital alemao oswaldo cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>xxviii domingo do tempo comum cor liturgica verde</td>\n",
       "      <td>6.0</td>\n",
       "      <td>paroquia sao sebastiao sao paulo sp</td>\n",
       "      <td>0</td>\n",
       "      <td>encerrado</td>\n",
       "      <td>devido as medidas restritivas as missas presen...</td>\n",
       "      <td>paroquia sao sebastiao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>ya experience sunrise</td>\n",
       "      <td>5.0</td>\n",
       "      <td>garage coworking sao paulo sp</td>\n",
       "      <td>95.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>experience sunrise a vida em movimento e o cam...</td>\n",
       "      <td>claudia faria fundadora do yoga adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>yoga outubrorosaflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parque ibirapuera estacionamento mam sao paulo sp</td>\n",
       "      <td>0</td>\n",
       "      <td>encerrado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>young living brasil de marco de</td>\n",
       "      <td>5.0</td>\n",
       "      <td>sao paulo expo sao paulo sp</td>\n",
       "      <td>60.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>queridos participantes preocupada com a saude ...</td>\n",
       "      <td>young living</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  dow  \\\n",
       "0                               culto de domingo manha  NaN   \n",
       "1                               culto de domingo noite  NaN   \n",
       "2                                      culto de quinta  NaN   \n",
       "3    o esladja e o aniversario da adja trabalhando ...  5.0   \n",
       "4                                    o piquenique azul  NaN   \n",
       "..                                                 ...  ...   \n",
       "884    xvi jornada paulista de neurofisiologia clinica  NaN   \n",
       "885  xxviii domingo do tempo comum cor liturgica verde  6.0   \n",
       "886                              ya experience sunrise  5.0   \n",
       "887                               yoga outubrorosaflow  1.0   \n",
       "888                    young living brasil de marco de  5.0   \n",
       "\n",
       "                                              location   price       info  \\\n",
       "0                                                  NaN       0        NaN   \n",
       "1                                                  NaN       0        NaN   \n",
       "2                                                  NaN       0        NaN   \n",
       "3                                r uhland sao paulo sp   25.00        NaN   \n",
       "4                                                  NaN       0        NaN   \n",
       "..                                                 ...     ...        ...   \n",
       "884                                                NaN  150.00        NaN   \n",
       "885                paroquia sao sebastiao sao paulo sp       0  encerrado   \n",
       "886                      garage coworking sao paulo sp   95.00        NaN   \n",
       "887  parque ibirapuera estacionamento mam sao paulo sp       0  encerrado   \n",
       "888                        sao paulo expo sao paulo sp   60.00        NaN   \n",
       "\n",
       "                                           description  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    em breve acontecera a nossa 10a esladja escola...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "884                                                NaN   \n",
       "885  devido as medidas restritivas as missas presen...   \n",
       "886  experience sunrise a vida em movimento e o cam...   \n",
       "887                                                NaN   \n",
       "888  queridos participantes preocupada com a saude ...   \n",
       "\n",
       "                                     organizer  \n",
       "0                         igreja monte carmelo  \n",
       "1                         igreja monte carmelo  \n",
       "2                         igreja monte carmelo  \n",
       "3                              email protected  \n",
       "4                    nathalia noschese natype1  \n",
       "..                                         ...  \n",
       "884               hospital alemao oswaldo cruz  \n",
       "885                     paroquia sao sebastiao  \n",
       "886  claudia faria fundadora do yoga adventure  \n",
       "887                                       flow  \n",
       "888                               young living  \n",
       "\n",
       "[889 rows x 7 columns]"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_info_sympla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining data and saving for manual labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([events_info_eb, events_info_sympla]).reset_index(drop=True)\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('./features_before_labeling.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data after labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data was randomly shuffled while labeling in order to mix events from both aggregator websites\n",
    "df = pd.read_csv(\"./features_with_labels.csv\", index_col=0).reset_index(drop=True)\n",
    "df = df.drop(['RAND'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing string columns for vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied tokenization, stopword removal and duplicate word removal in order to prepare text for vectorization  \n",
    "Stemming was not applied as default, but is implemented and can be performed by setting stem=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_text_processing(series, stem=False):\n",
    "    processed = []\n",
    "    for index, value in series.items():\n",
    "        if type(value) != float:\n",
    "            # Tokenization\n",
    "            value = word_tokenize(value)\n",
    "\n",
    "            # Stopword removal\n",
    "            value = [w for w in value if w not in stop_pt]\n",
    "\n",
    "            # Duplicate removal\n",
    "            value = list(unique_everseen(value))\n",
    "\n",
    "            # Stemming\n",
    "            if stem:\n",
    "                stemmer = RSLPStemmer()\n",
    "                value = [stemmer.stem(w) for w in value]\n",
    "\n",
    "            value = \" \".join(value)\n",
    "        \n",
    "        processed.append(value)\n",
    "    \n",
    "    return pd.Series(processed, name=series.name)\n",
    "\n",
    "def df_text_processing(df, cols, stem=False):\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = df[df.columns.difference(cols)]\n",
    "    \n",
    "    for c in cols:\n",
    "        aux_df = pd.concat([aux_df, col_text_processing(df[c], stem)], axis=1)\n",
    "    \n",
    "    return aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info column not selected as feature for having too few non-null values and not so relevant information\n",
    "text_cols = ['name', 'location', 'description', 'organizer']\n",
    "# Diff as in different from textual\n",
    "diff_cols = df.columns.difference(text_cols)\n",
    "diff_cols = diff_cols.drop(['info', 'y'])\n",
    "\n",
    "# Remove rows with null values on the text_cols\n",
    "df.dropna(axis=0, subset=text_cols, how='any', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Process text_cols\n",
    "df = df_text_processing(df, text_cols)\n",
    "\n",
    "# Saving labels\n",
    "y = df['y'].copy()\n",
    "df.drop('y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data - train & valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train: 34, y valid: 18\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size = 0.35, random_state=0)\n",
    "print(\"y train: {}, y valid: {}\".format(y_train.sum(), y_valid.sum()))\n",
    "\n",
    "X_train_diff = X_train[diff_cols].copy()\n",
    "X_valid_diff = X_valid[diff_cols].copy()\n",
    "X_train_text = X_train[text_cols].copy()\n",
    "X_valid_text = X_valid[text_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.0</td>\n",
       "      <td>487.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dow  price\n",
       "37   3.0    0.0\n",
       "143  6.0   40.0\n",
       "436  0.0  487.5\n",
       "158  5.0   15.0\n",
       "613  NaN    0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>organizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>exposicao luzes memoria</td>\n",
       "      <td>iac instituto arte contemporanea sao paulo sp</td>\n",
       "      <td>exposicao luzes memoria curadoria marilucia bo...</td>\n",
       "      <td>instituto arte contemporanea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>pool candy</td>\n",
       "      <td>local definir sao paulo sp</td>\n",
       "      <td>1 edicao pool candy line up breve hostess yasm...</td>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>c i m congresso internacional academico microp...</td>\n",
       "      <td>organizador nao aceita reembolsos art lei codi...</td>\n",
       "      <td>ciami congresso internacional academico microp...</td>\n",
       "      <td>renata constante barcelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>comedia solta</td>\n",
       "      <td>acustico business sao paulo sp</td>\n",
       "      <td>espetaculo stand up comedia solta iniciativa f...</td>\n",
       "      <td>acustico business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>curso energia solar hortolandia</td>\n",
       "      <td>hotel horto plaza hortolandia sp rua zacarias ...</td>\n",
       "      <td>curso energia solar hortolandia corte ate 100 ...</td>\n",
       "      <td>evento solar fotovoltaico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name  \\\n",
       "37                             exposicao luzes memoria   \n",
       "143                                         pool candy   \n",
       "436  c i m congresso internacional academico microp...   \n",
       "158                                      comedia solta   \n",
       "613                    curso energia solar hortolandia   \n",
       "\n",
       "                                              location  \\\n",
       "37       iac instituto arte contemporanea sao paulo sp   \n",
       "143                         local definir sao paulo sp   \n",
       "436  organizador nao aceita reembolsos art lei codi...   \n",
       "158                     acustico business sao paulo sp   \n",
       "613  hotel horto plaza hortolandia sp rua zacarias ...   \n",
       "\n",
       "                                           description  \\\n",
       "37   exposicao luzes memoria curadoria marilucia bo...   \n",
       "143  1 edicao pool candy line up breve hostess yasm...   \n",
       "436  ciami congresso internacional academico microp...   \n",
       "158  espetaculo stand up comedia solta iniciativa f...   \n",
       "613  curso energia solar hortolandia corte ate 100 ...   \n",
       "\n",
       "                        organizer  \n",
       "37   instituto arte contemporanea  \n",
       "143                          alex  \n",
       "436     renata constante barcelli  \n",
       "158             acustico business  \n",
       "613     evento solar fotovoltaico  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering - numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling price values with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit_transform on training data\n",
    "price_scaled_df = pd.DataFrame(X_train_diff['price'])\n",
    "price_scaled_df.rename(columns={'price':'price_scaled'}, inplace=True)\n",
    "price_array = X_train_diff['price'].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "price_scaled_array = scaler.fit_transform(price_array.reshape(-1,1))\n",
    "price_scaled_df = pd.DataFrame(price_scaled_array, columns=price_scaled_df.columns, index=price_scaled_df.index)\n",
    "\n",
    "X_train_diff.drop(['price'], axis=1, inplace=True)\n",
    "X_train_diff = pd.concat([X_train_diff, price_scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dow</th>\n",
       "      <th>price_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.927592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.266268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.977593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.333106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.477921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.087090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.477921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.477921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.477921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dow  price_scaled\n",
       "915   5.0      0.927592\n",
       "590   6.0     -0.266268\n",
       "108   NaN      0.042945\n",
       "833   0.0      1.977593\n",
       "1067  4.0      2.333106\n",
       "...   ...           ...\n",
       "870   0.0     -0.477921\n",
       "352   3.0     -0.087090\n",
       "95    5.0     -0.477921\n",
       "113   6.0     -0.477921\n",
       "796   0.0     -0.477921\n",
       "\n",
       "[407 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform on validation data\n",
    "price_scaled_df = pd.DataFrame(X_valid_diff['price'])\n",
    "price_scaled_df.rename(columns={'price':'price_scaled'}, inplace=True)\n",
    "price_array = X_valid_diff['price'].to_numpy()\n",
    "\n",
    "price_scaled_array = scaler.transform(price_array.reshape(-1,1))\n",
    "price_scaled_df = pd.DataFrame(price_scaled_array, columns=price_scaled_df.columns, index=price_scaled_df.index)\n",
    "\n",
    "X_valid_diff.drop(['price'], axis=1, inplace=True)\n",
    "X_valid_diff = pd.concat([X_valid_diff, price_scaled_df], axis=1)\n",
    "X_valid_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering - categorical & NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing mode for null DOW values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining mode from training data only\n",
    "mode_dow = X_train_diff['dow'].mode()\n",
    "X_train_diff['dow'].fillna(mode_dow[0], inplace=True)\n",
    "X_valid_diff['dow'].fillna(mode_dow[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming DOW column to dummy variables with OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "dow_array = X_train_diff['dow'].to_numpy()\n",
    "\n",
    "dow_encoder = OneHotEncoder()\n",
    "dow_1hot = dow_encoder.fit_transform(dow_array.reshape(-1,1))\n",
    "\n",
    "X_train_diff = pd.concat([X_train_diff, pd.DataFrame(dow_1hot.toarray(), index=X_train_diff.index)], axis=1)\n",
    "X_train_diff.drop(['dow'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data \n",
    "# As this is a OneHotEncoder, it wouldn't be necessary to do this this way, but it doesn't hurt to be consistent with the appropriate\n",
    "# treatment of training and validation data\n",
    "dow_array = X_valid_diff['dow'].to_numpy()\n",
    "\n",
    "dow_1hot = dow_encoder.transform(dow_array.reshape(-1,1))\n",
    "\n",
    "X_valid_diff = pd.concat([X_valid_diff, pd.DataFrame(dow_1hot.toarray(), index=X_valid_diff.index)], axis=1)\n",
    "X_valid_diff.drop(['dow'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_scaled</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.927592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>-0.266268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>1.977593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>2.333106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>-0.477921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.087090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.477921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.477921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-0.477921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price_scaled    0    1    2    3    4    5    6\n",
       "915       0.927592  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "590      -0.266268  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "108       0.042945  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "833       1.977593  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1067      2.333106  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "...            ...  ...  ...  ...  ...  ...  ...  ...\n",
       "870      -0.477921  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "352      -0.087090  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "95       -0.477921  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n",
       "113      -0.477921  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "796      -0.477921  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[407 rows x 8 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining function for fitting and transforming textual data (and also saving vectorizers for production purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_text(col_train, col_valid, min_df=1, ngram_range=(1,1), save=False):\n",
    "    \n",
    "    vect = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    text_features_train = vect.fit_transform(col_train)\n",
    "    #print(\"# features for {}: {}\".format(col_train.name, text_features_train.shape[1]))\n",
    "    text_features_valid = vect.transform(col_valid)\n",
    "    \n",
    "    if save:\n",
    "        jb.dump(vect, \"./Deploy/vect_{}.pkl.z\".format(col_train.name))\n",
    "        \n",
    "    return text_features_train, text_features_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining default hyperparameters for some models\n",
    "\n",
    "# Random Forest (RF) default\n",
    "rf_default = dict()\n",
    "rf_default['n_estimators'], rf_default['max_depth'], rf_default['min_samples_split'], rf_default['min_samples_leaf'] = 100, None, 2, 1\n",
    "rf_default['max_features'], rf_default['bootstrap'] = 'auto', True\n",
    "\n",
    "# Light GBM (LGBM) default\n",
    "lgbm_default = dict()\n",
    "lgbm_default['n_estimators'], lgbm_default['max_depth'], lgbm_default['min_child_samples'], lgbm_default['subsample'] = 100, -1, 20, 1\n",
    "lgbm_default['colsample_bytree'], lgbm_default['learning_rate'] = 1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimal hyperparameters for some models (obtained after running optimization functions below)\n",
    "\n",
    "# RF parameters\n",
    "rf_params = dict()\n",
    "rf_params['n_estimators'], rf_params['max_depth'], rf_params['min_samples_split'], rf_params['min_samples_leaf'] = 763, 5, 20, 10\n",
    "rf_params['max_features'], rf_params['bootstrap'] = 'sqrt', False\n",
    "class_weight_rf = 'balanced'\n",
    "min_df_rf = 2\n",
    "ngram_range_rf = (1,1)\n",
    "diff_feats_rf = False\n",
    "\n",
    "# LGBM parameters\n",
    "lgbm_params = dict()\n",
    "lgbm_params['n_estimators'], lgbm_params['max_depth'], lgbm_params['min_child_samples'], lgbm_params['subsample'] = 650, 6, 11, 0.11295588601409831\n",
    "lgbm_params['colsample_bytree'], lgbm_params['learning_rate'] = 0.09968988985022398, 0.0018192116907497335\n",
    "class_weight_lgbm = 'balanced'\n",
    "min_df_lgbm = 4\n",
    "ngram_range_lgbm = (1,5)\n",
    "diff_feats_lgbm = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions for training and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(m_type, name, save=False, rf_params=rf_default, lgbm_params=lgbm_default, \\\n",
    "                 diff_feats=True, class_weight='balanced', min_df=1, ngram_range=(1,1)):\n",
    "    m = dict()\n",
    "    m['m_type'], m['name'], m['diff_feats'], m['class_weight'] = m_type, name, diff_feats, class_weight\n",
    "    m['min_df'], m['ngram_range'], m['rf_params'], m['lgbm_params'], m['save'] = min_df, ngram_range, rf_params, lgbm_params, save\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(m_type, name, save, rf_params=rf_default, lgbm_params=lgbm_default, \\\n",
    "                         diff_feats=True, class_weight='balanced', min_df=1, ngram_range=(1,1)):\n",
    "    \n",
    "    models = {\n",
    "        'lr': LogisticRegression(C=0.8, penalty='l2', n_jobs=6, random_state=0),\n",
    "        'tree': DecisionTreeClassifier(class_weight=class_weight, random_state=0),\n",
    "        'rf': RandomForestClassifier(n_estimators=rf_params['n_estimators'], max_depth=rf_params['max_depth'], \\\n",
    "                                     min_samples_split=rf_params['min_samples_split'], min_samples_leaf=rf_params['min_samples_leaf'], \\\n",
    "                                     max_features=rf_params['max_features'], bootstrap=rf_params['bootstrap'], class_weight=class_weight, \\\n",
    "                                     n_jobs=6, random_state=0),\n",
    "        'lgbm': LGBMClassifier(n_estimators=lgbm_params['n_estimators'], max_depth=lgbm_params['max_depth'], \\\n",
    "                                     min_child_samples=lgbm_params['min_child_samples'], subsample=lgbm_params['subsample'], \\\n",
    "                                     colsample_bytree=lgbm_params['colsample_bytree'], learning_rate=lgbm_params['learning_rate'], \\\n",
    "                                     class_weight=class_weight, n_jobs=6, random_state=0)\n",
    "    }  \n",
    "    \n",
    "    X_train = pd.DataFrame()\n",
    "    X_valid = pd.DataFrame()\n",
    "    \n",
    "    for c in text_cols:\n",
    "        text_features_train, text_features_valid = fit_transform_text(X_train_text[c], X_valid_text[c], min_df=min_df, ngram_range=ngram_range, \\\n",
    "                                                                      save=save)\n",
    "        X_train = hstack([X_train, text_features_train])\n",
    "        X_valid = hstack([X_valid, text_features_valid])\n",
    "    \n",
    "    if diff_feats:\n",
    "        X_train = hstack([X_train_diff, X_train])\n",
    "        X_valid = hstack([X_valid_diff, X_valid])\n",
    "    \n",
    "    model = models.get(m_type, '')\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    # Train data\n",
    "    prob_train = model.predict_proba(X_train)[:,1]\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    \n",
    "    # Valid data\n",
    "    prob_valid = model.predict_proba(X_valid)[:,1]\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    \n",
    "    evaluation_dict = dict()\n",
    "    evaluation_dict['model_type'] = m_type\n",
    "    evaluation_dict['name'] = name\n",
    "    evaluation_dict['train_miscl_error'] = 1-accuracy_score(y_train, y_pred_train)\n",
    "    evaluation_dict['valid_miscl_error'] = 1-accuracy_score(y_valid, y_pred_valid)\n",
    "    evaluation_dict['average_precision'] = average_precision_score(y_valid, prob_valid)\n",
    "    evaluation_dict['auc'] = roc_auc_score(y_valid, prob_valid)\n",
    "    evaluation_dict['accuracy'] = accuracy_score(y_valid, y_pred_valid)\n",
    "    evaluation_dict['precision'] = precision_score(y_valid, y_pred_valid)\n",
    "    evaluation_dict['recall'] = recall_score(y_valid, y_pred_valid)\n",
    "    evaluation_dict['f1_score'] = f1_score(y_valid, y_pred_valid)\n",
    "    \n",
    "    \n",
    "    return model, evaluation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(eval_dict_list):\n",
    "    \n",
    "    df = pd.DataFrame(eval_dict_list)\n",
    "    \n",
    "    # idxmax: returns index of row with max column value\n",
    "    m_max_ap = df.iloc[df['average_precision'].idxmax()]['name']\n",
    "    m_max_auc = df.iloc[df['auc'].idxmax()]['name']\n",
    "    m_max_accuracy = df.iloc[df['accuracy'].idxmax()]['name']\n",
    "    m_max_precision = df.iloc[df['precision'].idxmax()]['name']\n",
    "    m_max_recall = df.iloc[df['recall'].idxmax()]['name']\n",
    "    m_max_f1 = df.iloc[df['f1_score'].idxmax()]['name']\n",
    "    \n",
    "    print('VALIDATION DATA RESULTS')\n",
    "    print('Highest AP: {}\\nHighest AUC: {}\\nHighest ACCURACY: {}\\nHighest PRECISION: {}\\nHighest RECALL: {}\\nHighest F1: {}\\n'.format(m_max_ap, m_max_auc, m_max_accuracy, m_max_precision, m_max_recall, m_max_f1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "lr_dict = define_model(m_type='lr', name='lr', min_df=1, ngram_range=(1,1))\n",
    "\n",
    "tree_dict = define_model(m_type='tree', name='tree', class_weight=None, min_df=1, ngram_range=(1,1))\n",
    "tree_balanced_dict = define_model(m_type='tree', name='tree_balanced', class_weight='balanced', min_df=1, ngram_range=(1,1))\n",
    "tree_min_df_dict = define_model(m_type='tree', name='tree_min_df', class_weight=None, min_df=2, ngram_range=(1,1))\n",
    "tree__min_df_balanced_dict = define_model(m_type='tree', name='tree_min_df_balanced', class_weight='balanced', min_df=2, ngram_range=(1,1))\n",
    "\n",
    "rf_default_dict = define_model(m_type='rf', name='rf_default', rf_params=rf_default, class_weight='balanced', min_df=1, ngram_range=(1,1))\n",
    "rf_params_dict = define_model(m_type='rf', name='rf_params', save=True, rf_params=rf_params, diff_feats=diff_feats_rf, class_weight=class_weight_rf, \\\n",
    "                              min_df=min_df_rf, ngram_range=ngram_range_rf)\n",
    "\n",
    "lgbm_default_dict = define_model(m_type='lgbm', name='lgbm_default', lgbm_params=lgbm_default, class_weight='balanced', min_df=1, ngram_range=(1,1))\n",
    "lgbm_params_dict = define_model(m_type='lgbm', name='lgbm_params', lgbm_params=lgbm_params, diff_feats=diff_feats_lgbm, class_weight=class_weight_lgbm, \\\n",
    "                                min_df=min_df_lgbm, ngram_range=ngram_range_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec_list = [lr_dict, tree_dict, tree_balanced_dict, tree_min_df_dict, tree__min_df_balanced_dict, \\\n",
    "                   rf_default_dict, rf_params_dict, lgbm_default_dict, lgbm_params_dict]\n",
    "\n",
    "model_list = []\n",
    "eval_dict_list = []\n",
    "\n",
    "for m in model_spec_list:\n",
    "    model, evaluation_dict = train_evaluate_model(m['m_type'], m['name'], save=m['save'], rf_params=m['rf_params'], lgbm_params=m['lgbm_params'], \\\n",
    "                            diff_feats=m['diff_feats'], class_weight=m['class_weight'], min_df=m['min_df'], ngram_range=m['ngram_range'])\n",
    "    model_list.append(model)\n",
    "    eval_dict_list.append(evaluation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA RESULTS\n",
      "Highest AP: lr\n",
      "Highest AUC: lr\n",
      "Highest ACCURACY: rf_params\n",
      "Highest PRECISION: lr\n",
      "Highest RECALL: tree_min_df\n",
      "Highest F1: rf_params\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>name</th>\n",
       "      <th>train_miscl_error</th>\n",
       "      <th>valid_miscl_error</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>lr</td>\n",
       "      <td>0.031830</td>\n",
       "      <td>0.034398</td>\n",
       "      <td>0.600742</td>\n",
       "      <td>0.874607</td>\n",
       "      <td>0.965602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>tree</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.251138</td>\n",
       "      <td>0.759783</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tree</td>\n",
       "      <td>tree_balanced</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073710</td>\n",
       "      <td>0.151554</td>\n",
       "      <td>0.696515</td>\n",
       "      <td>0.926290</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>tree_min_df</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.791417</td>\n",
       "      <td>0.955774</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tree</td>\n",
       "      <td>tree_min_df_balanced</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>0.127850</td>\n",
       "      <td>0.668738</td>\n",
       "      <td>0.923833</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf</td>\n",
       "      <td>rf_default</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.566121</td>\n",
       "      <td>0.852614</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>rf_params</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.022113</td>\n",
       "      <td>0.584657</td>\n",
       "      <td>0.842616</td>\n",
       "      <td>0.977887</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>lgbm_default</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.514616</td>\n",
       "      <td>0.785990</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>lgbm_params</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.024570</td>\n",
       "      <td>0.488398</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.975430</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                  name  train_miscl_error  valid_miscl_error  \\\n",
       "0         lr                    lr           0.031830           0.034398   \n",
       "1       tree                  tree           0.000000           0.054054   \n",
       "2       tree         tree_balanced           0.000000           0.073710   \n",
       "3       tree           tree_min_df           0.000000           0.044226   \n",
       "4       tree  tree_min_df_balanced           0.000000           0.076167   \n",
       "5         rf            rf_default           0.000000           0.029484   \n",
       "6         rf             rf_params           0.009284           0.022113   \n",
       "7       lgbm          lgbm_default           0.000000           0.029484   \n",
       "8       lgbm           lgbm_params           0.003979           0.024570   \n",
       "\n",
       "   average_precision       auc  accuracy  precision    recall  f1_score  \n",
       "0           0.600742  0.874607  0.965602   1.000000  0.222222  0.363636  \n",
       "1           0.251138  0.759783  0.945946   0.416667  0.555556  0.476190  \n",
       "2           0.151554  0.696515  0.926290   0.285714  0.444444  0.347826  \n",
       "3           0.322755  0.791417  0.955774   0.500000  0.611111  0.550000  \n",
       "4           0.127850  0.668738  0.923833   0.259259  0.388889  0.311111  \n",
       "5           0.566121  0.852614  0.970516   0.875000  0.388889  0.538462  \n",
       "6           0.584657  0.842616  0.977887   0.909091  0.555556  0.689655  \n",
       "7           0.514616  0.785990  0.970516   0.875000  0.388889  0.538462  \n",
       "8           0.488398  0.802985  0.975430   0.900000  0.500000  0.642857  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = compare_models(eval_dict_list)\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen model: rf_params (optimized random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not overfitting training data: > 0 train misclassification error (ME)   \n",
    "- Highest accuracy with validation data (lowest validation ME)  \n",
    "- Highest F1-score with validation data\n",
    "- Second highest recall with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_list[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfIdf Vectorizers for chosen model were saved by running define_model with save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb.dump(model, \"./Deploy/model.pkl.z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization functions: optimizing for highest F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF Optimization\n",
    "def optimize_rf(params):\n",
    "    \n",
    "    print(params)\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_samples_split = params[2]\n",
    "    min_samples_leaf = params[3]\n",
    "    max_features = params[4] \n",
    "    bootstrap = params[5]\n",
    "    class_weight = params[6]\n",
    "    min_df = params[7] \n",
    "    ngram_range = (1, params[8])\n",
    "    diff_feats = params[9]\n",
    "    \n",
    "    X_train = pd.DataFrame()\n",
    "    X_valid = pd.DataFrame()\n",
    "    \n",
    "    for c in text_cols:\n",
    "        text_features_train, text_features_valid = fit_transform_text(X_train_text[c], X_valid_text[c], min_df=min_df, ngram_range=ngram_range)\n",
    "        X_train = hstack([X_train, text_features_train])\n",
    "        X_valid = hstack([X_valid, text_features_valid])\n",
    "    \n",
    "    if diff_feats:\n",
    "        X_train = hstack([X_train_diff, X_train])\n",
    "        X_valid = hstack([X_valid_diff, X_valid])\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, \\\n",
    "                                   min_samples_leaf=min_samples_leaf, max_features=max_features, bootstrap=bootstrap, class_weight=class_weight, \\\n",
    "                                   n_jobs=6, random_state=0, )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1 Score: {}\".format(round(accuracy_score(y_valid, y_pred), 4), \\\n",
    "                round(precision_score(y_valid, y_pred), 4), round(recall_score(y_valid, y_pred), 4), round(f1_score(y_valid, y_pred), 4)))\n",
    "    \n",
    "    return -f1_score(y_valid, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_rf = [(100,1000), # n_estimators\n",
    "          (1, 10), # max_depth\n",
    "          (2, 20), # min_samples_split\n",
    "          (1, 10), # min_samples_leaf\n",
    "          ('sqrt', 'log2', None), # max_features\n",
    "          (True, False), # bootstrap\n",
    "          ('balanced', None), # class_weight\n",
    "          (1,5), # min_df\n",
    "          (1,5), # ngram_range\n",
    "          (True, False)] # diff_feats\n",
    "\n",
    "# Sequential optimization using decision trees\n",
    "opt_rf = forest_minimize(optimize_rf, space_rf, n_random_starts=20, n_calls=60, verbose=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([763, 5, 20, 10, 'sqrt', False, 'balanced', 2, 1, False], -0.6896551724137931)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_rf.x, opt_rf.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM Optimization\n",
    "def optimize_lgbm(params):\n",
    "    \n",
    "    print(params)\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4] \n",
    "    learning_rate = params[5]\n",
    "    min_df = params[6] \n",
    "    ngram_range = (1, params[7])\n",
    "    diff_feats = params[8]\n",
    "    \n",
    "    X_train = pd.DataFrame()\n",
    "    X_valid = pd.DataFrame()\n",
    "    \n",
    "    for c in text_cols:\n",
    "        text_features_train, text_features_valid = fit_transform_text(X_train_text[c], X_valid_text[c], min_df=min_df, ngram_range=ngram_range)\n",
    "        X_train = hstack([X_train, text_features_train])\n",
    "        X_valid = hstack([X_valid, text_features_valid])\n",
    "    \n",
    "    if diff_feats:\n",
    "        X_train = hstack([X_train_diff, X_train])\n",
    "        X_valid = hstack([X_valid_diff, X_valid])\n",
    "    \n",
    "    model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, min_child_samples=min_child_samples, \\\n",
    "                                     subsample=subsample, colsample_bytree=colsample_bytree, learning_rate=learning_rate, \\\n",
    "                                     class_weight='balanced', num_leaves=2**max_depth, n_jobs=6, random_state=0)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1 Score: {}\".format(round(accuracy_score(y_valid, y_pred), 4), \\\n",
    "                round(precision_score(y_valid, y_pred), 4), round(recall_score(y_valid, y_pred), 4), round(f1_score(y_valid, y_pred), 4)))\n",
    "    \n",
    "    return -f1_score(y_valid, y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_lgbm = [(100,1000), # n_estimators,\n",
    "         (1, 10), # max_depth\n",
    "         (1, 20), # min_child_samples\n",
    "         (0.05, 1.), # subsample\n",
    "         (0.05, 1.), # colsample_bytree\n",
    "         (1e-3, 1e-1, 'log-uniform'), # learning_rate\n",
    "         (1,5), # min_df\n",
    "         (1,5), # ngram_range\n",
    "         (True,False)] # diff_feats\n",
    "\n",
    "# Sequential optimization using decision trees\n",
    "opt_lgbm = forest_minimize(optimize_lgbm, space_lgbm, n_random_starts=20, n_calls=60, verbose=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([650,\n",
       "  6,\n",
       "  11,\n",
       "  0.11295588601409831,\n",
       "  0.09968988985022398,\n",
       "  0.0018192116907497335,\n",
       "  4,\n",
       "  5,\n",
       "  False],\n",
       " -0.6428571428571429)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_lgbm.x, opt_lgbm.fun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
